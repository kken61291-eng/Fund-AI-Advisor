name: Daily Data Crawler

on:
  schedule:
    # åŒ—äº¬æ—¶é—´å·¥ä½œæ—¥ 11:00, 12:00, 13:00, 14:00 è¿è¡Œ
    # GitHub Actions ä½¿ç”¨ UTC æ—¶é—´ï¼Œå¯¹åº”ä¸º 03:00, 04:00, 05:00, 06:00
    - cron: '0 3-6 * * 1-5'
  workflow_dispatch:

# å¿…é¡»èµ‹äºˆå†™å…¥æƒé™
permissions:
  contents: write

jobs:
  fetch_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        # [å…³é”®] è·å–å®Œæ•´å†å²ï¼Œé¿å… push å†²çª
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        # å¼ºåˆ¶å‡çº§ akshare åˆ°æœ€æ–°ç‰ˆ
        pip install --upgrade akshare

    # ----------------------------------------------------------------
    # æ­¥éª¤ 1: æŠ“å– åŸºé‡‘äº¤æ˜“/è¡Œæƒ…æ•°æ® (Market)
    # ----------------------------------------------------------------
    - name: ğŸ“ˆ Run Market Data Fetcher
      # ğŸŸ¢ [å…³é”®ä¿®æ”¹] å°† Secret æ³¨å…¥åˆ°ç¯å¢ƒå˜é‡ï¼Œä¾› Python è¯»å–
      env:
        SCRAPERAPI_KEY: ${{ secrets.SCRAPERAPI_KEY }}
      # æ³¨æ„ï¼šç”±äºä»£ç ä¸­å¢åŠ äº†ä¸œè´¢50ç§’å»¶æ—¶ï¼Œè¯·ç¡®ä¿æ€»è¿è¡Œæ—¶é—´ä¸è¶…è¿‡6å°æ—¶
      run: |
        python data_fetcher.py

    # ----------------------------------------------------------------
    # æ­¥éª¤ 2: æŠ“å– 7x24 å…¨çƒè´¢ç»ç”µæŠ¥ (News)
    # ----------------------------------------------------------------
    - name: ğŸ•·ï¸ Run News Crawler
      # ğŸŸ¢ [å…³é”®ä¿®æ”¹] åŒæ ·æ³¨å…¥ Keyï¼Œé˜²æ­¢æ–°é—»æ¥å£ä¹Ÿéœ€è¦ä»£ç†
      env:
        SCRAPERAPI_KEY: ${{ secrets.SCRAPERAPI_KEY }}
      run: |
        python news_loader.py

    # ----------------------------------------------------------------
    # æ­¥éª¤ 3: æäº¤å¹¶ä¿å­˜æ•°æ®
    # ----------------------------------------------------------------
    - name: ğŸ’¾ Commit and Push Data
      run: |
        # é…ç½® git ç”¨æˆ·
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"

        # æ·»åŠ æ•°æ®ç›®å½•
        git add data_news/
        git add data_cache/ || true

        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŠ¨
        if [[ -n $(git status --porcelain) ]]; then
          echo "æ£€æµ‹åˆ°æ•°æ®æ›´æ–°ï¼Œæ­£åœ¨æäº¤..."
          git commit -m "ğŸ“¡ Auto-update News & Market data [skip ci]"

          # [å…³é”®ä¿®å¤] å…ˆæ‹‰å–è¿œç¨‹æ›´æ–°ï¼Œé¿å…å†²çª
          echo "æ­£åœ¨åŒæ­¥è¿œç¨‹æ›´æ”¹..."
          git pull origin main --rebase || git pull origin master --rebase || true

          # æ¨é€ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
          for i in 1 2 3; do
            echo "å°è¯•æ¨é€ (ç¬¬ $i æ¬¡)..."
            git push && break
            echo "æ¨é€å¤±è´¥ï¼Œç­‰å¾…åé‡è¯•..."
            sleep 3
            git pull --rebase
          done
        else
          echo "No new data found, skipping commit."
        fi
