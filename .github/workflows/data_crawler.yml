name: Daily Data Crawler

on:
  schedule:
    # æ¯å°æ—¶ç¬¬ 0 åˆ†é’Ÿè¿è¡Œ (æŠ“å–æ•°æ®)
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  fetch_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        # [å…³é”®] å¼ºåˆ¶å‡çº§ akshare åˆ°æœ€æ–°ç‰ˆï¼Œé˜²æ­¢ 7x24 æ¥å£å¤±æ•ˆ
        pip install --upgrade akshare

    - name: ğŸ•·ï¸ Run News Crawler
      run: |
        python news_loader.py

    - name: ğŸ’¾ Commit and Push Data
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        
        # æ·»åŠ  data_news ç›®å½•ä¸‹çš„æ‰€æœ‰å˜åŠ¨
        git add data_news/
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å˜åŒ–ï¼Œæœ‰åˆ™æäº¤ï¼Œæ— åˆ™è·³è¿‡
        if [[ -n $(git status --porcelain data_news/) ]]; then
          git commit -m "ğŸ“¡ Auto-update news data [skip ci]"
          git push
        else
          echo "No new data found, skipping commit."
        fi
