name: Data Crawler (Batch Updater)

on:
  schedule:
    # åŒ—äº¬æ—¶é—´ 08:30 - 15:30 æ¯å°æ—¶çˆ¬å–ä¸€æ¬¡
    - cron: '30 0-7 * * 1-5'
  workflow_dispatch:

concurrency: 
  group: data-crawler
  cancel-in-progress: false

jobs:
  update_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: ğŸ•·ï¸ Run Market Data Crawler
      env:
        # å¦‚æœçˆ¬è™«éœ€è¦ Tushareï¼Œè¯·ä¿ç•™è¿™ä¸ªï¼Œä¸éœ€è¦é‚®ä»¶å˜é‡
        TUSHARE_TOKEN: ${{ secrets.TUSHARE_TOKEN }}
      run: |
        python batch_updater.py

    - name: ğŸ“¡ Run News Crawler
      run: |
        python news_loader.py

    - name: Commit and Push Data
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        
        if [[ -n $(git status --porcelain data_cache/ data_news/) ]]; then
          git add data_cache/*.csv
          git add data_news/*.jsonl
          git commit -m "ğŸ’¾ Auto-save market & news data [skip ci]"
          git pull --rebase origin main
          git push
        else
          echo "No new data fetched."
        fi
