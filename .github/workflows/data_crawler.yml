name: Data Crawler (Batch Updater)

on:
  schedule:
    # UTCæ—¶é—´ 1:30 - 7:30ï¼Œå¯¹åº”åŒ—äº¬æ—¶é—´ 09:30 - 15:30
    # æ¯å°æ—¶çš„ç¬¬30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ (æ¶µç›–å¼€ç›˜æœŸé—´åŠæ”¶ç›˜)
    - cron: '30 1-7 * * 1-5'
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨è§¦å‘

concurrency: 
  group: data-crawler
  cancel-in-progress: false

jobs:
  update_data:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: ğŸ•·ï¸ Run Batch Updater
      env:
        # çˆ¬è™«å¯èƒ½åªéœ€è¦åŸºç¡€é…ç½®ï¼Œå¦‚æœæ¶‰åŠé€šçŸ¥å¯åŠ é‚®ä»¶é…ç½®
        TUSHARE_TOKEN: ${{ secrets.TUSHARE_TOKEN }}
      run: |
        # è¿è¡Œæ‚¨ä¹‹å‰ä¿å­˜çš„ batch_updater.py
        # è¿™ä¸ªè„šæœ¬é‡ŒåŒ…å«äº†"æ¯æŠ“ä¸€ä¸ªæ¿å—ä¼‘çœ 60ç§’"çš„é€»è¾‘
        python batch_updater.py

    - name: Commit and Push Data Cache
      run: |
        git config --global user.name "GitHub Action"
        git config --global user.email "action@github.com"
        
        # æ£€æŸ¥ data_cache ç›®å½•æ˜¯å¦æœ‰å˜åŒ–
        if [[ -n $(git status --porcelain data_cache/) ]]; then
          git add data_cache/*.csv
          git commit -m "ğŸ’¾ Auto-save market data cache [skip ci]"
          
          # [å…³é”®] æ‹‰å–æœ€æ–°ä»£ç é˜²æ­¢ä¸åˆ†æä»»åŠ¡å†²çª
          git pull --rebase origin main
          git push
        else
          echo "No new data fetched."
        fi
